# -*- coding: utf-8 -*-
"""201901202_Project1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bJC8j1CsLWRygVrnX6eR2Hj2AkYGHhtH
"""

import numpy as np
import math
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.preprocessing import scale
from sklearn.model_selection import train_test_split
from sklearn import datasets

def initialization (input_size , hidden_layer_size , output_size):
    W1 = np.random.randn(hidden_layer_size, input_size) * 0.01
    b1 = np.ones((hidden_layer_size, 1))
    W2 = np.random.randn(output_size, hidden_layer_size) * 0.01
    b2 = np.ones((output_size, 1))
    initialization_dictionary = {'W1' : W1 , 'W2' : W2 , 'b1' : b1 , 'b2' : b2 }
    return initialization_dictionary

def general_initialization(dimension_array):
    np.random.seed(3)
    general_dictionary = {}
    for i in range ( 1 , len(dimension_array)):
      current = dimension_array[i]
      prev = dimension_array[i-1]
      general_dictionary['W' + str(i)] = np.random.randn(current , prev) *0.01
      general_dictionary['b' + str(i)] = np.ones((current , 1))
    return general_dictionary

test = general_initialization([5,4,3,2])
print(test)

def relu(x):
  result = np.maximum(0,x)
  value = x
  return result , value

def softmax(x):
  result = np.exp(x) / np.sum(np.exp(x))
  value = x
  return result, value

def back_relu(D, O):
  x = O
  result =  np.array(D, copy = True)
  result[x <= 0] = 0
  return result

def back_softmax (D, O):
   x = O
   result = (1 -softmax(x)[0]) * (softmax(x)[0])
   return result*D

def forward(OI, W, b):
    x = np.dot(W, OI) + b
    store = (OI, W, b)
    return x, store

def forward_apply_function (OI, w, b, Required_Function):
  if Required_Function == "Relu":
    x, f_store = forward(OI, w, b)
    result, value = relu(x)
  elif Required_Function == "Softmax":
    x, f_store = forward(OI, w, b)
    result, value = softmax(x)

  store = (f_store, value)
  return result , store

def general_forward(X, initialezed_p):
    general_store = []
    temp = X
    for i in range(1, len(initialezed_p)//2):
        oi =  temp
        temp, store = forward_apply_function(oi, initialezed_p['W' + str(i)], initialezed_p['b' + str(i)], 'Relu')
        general_store.append(store)

    Output, store = forward_apply_function(temp, initialezed_p['W' + str(len(initialezed_p)//2)], initialezed_p['b' + str(len(initialezed_p)//2)], 'Softmax')
    general_store.append(store)
    return Output, general_store

def backward(D, store):
    oi, W, b = store
    temp = oi.shape[1]
    dW = (1./temp) * np.dot(D, oi.T)
    db = (1./temp) * np.sum(D, axis=1, keepdims=True)
    result = np.dot(W.T, D)
    return result, dW, db

def backward_apply_function(D , store , Required_Function):
  store1, store2 = store
  if Required_Function == "Relu":
    d = back_relu(D, store2)
    result, dW, db= backward(d,store1)
  elif Required_Function == "Softmax":
    d = back_softmax(D, store2)
    result, dW, db= backward(d,store1)
  return result , dW , db

def general_backward(X , Y , storage):
  dictionary = {}
  temp1 = X.shape
  temp2 = np.full(temp1,0)
  temp2[Y,0] =1
  Y = temp2
  dx = - (np.divide(Y, X) - np.divide(1 - Y, 1 - X))
  next_store = storage[len(storage) - 1]
  result, dW_temp, db_temp = backward_apply_function(dx, next_store, "Softmax")
  dictionary['dA' + str(len(storage)-1)] = result
  dictionary['dW' + str(len(storage))] = dW_temp
  dictionary['db' + str(len(storage))] = db_temp
  for i in reversed(range(len(storage)-1)):
        current_store = storage[i]
        result2, dW_temp, db_temp = backward_apply_function(dictionary["dA" + str(i + 1)], current_store,"Relu")
        dictionary["dA" + str(i)] = result2
        dictionary["dW" + str(i + 1)] = dW_temp
        dictionary["db" + str(i + 1)] = db_temp
  return dictionary

def update(p_dictionary, g_dictionary, rate):
    P = p_dictionary.copy()
    for i in range(len(P) // 2):
      P["W" + str(i+1)] = P["W" + str(i+1)] - rate * g_dictionary["dW" + str(i+1)]
      P["b" + str(i+1)] = P["b" + str(i+1)] - rate * g_dictionary["db" + str(i+1) ]
    return P

def Accuracy(X_test, Y_test, x_size ,parameters):
  c = 0
  for i in range(len(X_test)):
      result , store = general_forward(np.reshape(X_test[i],(x_size,1)),parameters)
      predicted = np.argmax(result)
      if predicted == Y_test[i]:
        c = c + 1
  acc = (c / len(Y_test)) * 100
  return acc

from google.colab import drive
drive.mount('/content/drive')

train = pd.read_csv("/content/drive/MyDrive/Lab4 dataset/train.csv")
test = pd.read_csv("/content/drive/MyDrive/Lab4 dataset/test.csv")
x = train.iloc[:, 1:]
Y = train.iloc[:, 0]
x = x/255.0
X = scale(x)
X0train, X0test, Y0train, Y0test = train_test_split(X, Y, test_size = 0.25, train_size = 0.75 ,random_state = 20)
input_size = X0train.shape[1]
output_size = 10
Y_train = Y0train.tolist()
X_train = X0train.tolist()
I_Parameters = general_initialization ([input_size ,16,16,16, output_size]) #3 hidden layers
parameters = I_Parameters
for i in range (len(X_train)):
   result , store = general_forward(np.reshape(X_train[i],(input_size,1)),parameters)
   g_dictionary  = general_backward(result,np.array(Y_train[i]),store)
   parameters  = update(parameters,g_dictionary,0.01)

Y_test = Y0test.tolist()
X_test = X0test.tolist()
acc = Accuracy(X_test, Y_test, input_size, parameters)
print (f'Model Accuracy On MNIST dataset is {acc}%')

raw_data= datasets.load_iris()
iris = pd.DataFrame(raw_data.data, columns = raw_data.feature_names)
iris['target'] = raw_data.target
X2 = raw_data.data
Y2 = raw_data.target
IX_Train ,  IX_Test, IY_Train, IY_Test = train_test_split(X2,Y2 ,test_size= 0.25, train_size = 0.75 ,random_state = 20)
input_size2 = IX_Train.shape[1]
output_size2 = 3
I_Parameters2 = general_initialization ([input_size2 ,5,5,5, output_size2]) #3 hidden layers
parameters2 = I_Parameters2
for _ in range(150):
  for i in range (len(IX_Train)):
      AL , cache = general_forward(np.reshape(IX_Train[i],(input_size2,1)),parameters2)
      grad_dict  = general_backward(AL,np.array(IY_Train[i]),cache)
      parameters2  = update(parameters2,grad_dict,0.01)

acc = Accuracy(IX_Test, IY_Test, input_size2, parameters2)
print (f'Model Accuracy On IRIS dataset is {acc}%')